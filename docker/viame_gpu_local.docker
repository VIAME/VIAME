# syntax=docker/dockerfile:1.5.0
##############################################################################
# This Dockerfile defines an image suitable for development. It will build a
# baseline VIAME system, but it will not clean up source and build artifacts.
# This allows the developer to mount a local copy of the repo from their
# hostmachine onto this image, and then point the internal repo at the mounted
# directory containing the local host machine repo. This allows the developer
# to quickly pull changes into a running and rebuild from a warm start.
##############################################################################
FROM nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04

USER root

WORKDIR /home

RUN --mount=type=bind,target=/host-viame <<EOF
export DEBIAN_FRONTEND=noninteractive
export TZ=Etc/UTC 
apt-get update 
apt-get install -y git 

# Clone from the host machine to the new docker repo.
git clone --single-branch --dissociate /host-viame /viame 


cd /viame/cmake 

# Fletch, VIAME, CMAKE system deps
/viame/cmake/build_server_deps_apt.sh

# Install CMAKE
/viame/cmake/build_server_linux_cmake.sh

# Update VIAME sub git deps
cd /viame/
git submodule update --init --recursive

mkdir -p /viame/build
cd /viame/build

# Add VIAME and CUDA paths to build
export PATH=$PATH:/usr/local/cuda/bin:/viame/build/install/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/viame/build/install/lib:/usr/local/cuda/lib64

# Add paths for internal python build
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/viame/build/install/lib/python3.10
export C_INCLUDE_PATH=$C_INCLUDE_PATH:/viame/build/install/include/python3.10
export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/viame/build/install/include/python3.10

# Configure VIAME
# This can be updated based on development needs
cmake ../ -DCMAKE_BUILD_TYPE:STRING=Release \
-DVIAME_BUILD_DEPENDENCIES:BOOL=ON \
-DVIAME_FIXUP_BUNDLE:BOOL=OFF \
-DVIAME_VERSION_RELEASE:BOOL=ON \
-DVIAME_ENABLE_CUDA:BOOL=ON \
-DVIAME_ENABLE_CUDNN:BOOL=ON \
-DVIAME_ENABLE_DARKNET:BOOL=ON \
-DVIAME_ENABLE_DIVE:BOOL=OFF \
-DVIAME_ENABLE_DOCS:BOOL=OFF \
-DVIAME_ENABLE_FFMPEG:BOOL=ON \
-DVIAME_ENABLE_FFMPEG-X264:BOOL=ON \
-DVIAME_ENABLE_GDAL:BOOL=OFF \
-DVIAME_ENABLE_FLASK:BOOL=OFF \
-DVIAME_ENABLE_ITK:BOOL=OFF \
-DVIAME_ENABLE_KWANT:BOOL=ON \
-DVIAME_ENABLE_KWIVER:BOOL=ON \
-DVIAME_ENABLE_PYTORCH-LEARN:BOOL=OFF \
-DVIAME_ENABLE_MATLAB:BOOL=OFF \
-DVIAME_ENABLE_OPENCV:BOOL=ON \
-DVIAME_OPENCV_VERSION:STRING=3.4.0 \
-DVIAME_ENABLE_PYTHON:BOOL=ON \
-DVIAME_BUILD_PYTHON_FROM_SOURCE:BOOL=ON \
-DVIAME_ENABLE_PYTORCH:BOOL=ON \
-DVIAME_BUILD_PYTORCH_FROM_SOURCE:BOOL=ON \
-DVIAME_PYTORCH_VERSION:STRING=2.5.1 \
-DVIAME_BUILD_LIMIT_NINJA=ON \
-DVIAME_BUILD_TORCHVISION_FROM_SOURCE=ON \
-DVIAME_ENABLE_PYTORCH-VISION:BOOL=ON \
-DVIAME_ENABLE_PYTORCH-MMDET:BOOL=OFF \
-DVIAME_ENABLE_PYTORCH-NETHARN:BOOL=OFF \
-DVIAME_ENABLE_PYTORCH-MIT-YOLO:BOOL=ON \
-DVIAME_ENABLE_PYTORCH-SIAMMASK:BOOL=OFF \
-DVIAME_ENABLE_PYTORCH-SAM2:BOOL=ON \
-DVIAME_ENABLE_SEAL:BOOL=OFF \
-DVIAME_ENABLE_TENSORFLOW:BOOL=OFF \
-DVIAME_ENABLE_VIVIA:BOOL=OFF \
-DVIAME_ENABLE_VXL:BOOL=ON \
-DVIAME_ENABLE_WEB_EXCLUDES:BOOL=ON \
-DVIAME_DOWNLOAD_MODELS:BOOL=ON \
-DVIAME_DOWNLOAD_MODELS-PYTORCH:BOOL=OFF \
-DVIAME_DOWNLOAD_MODELS-GENERIC:BOOL=ON \
-DVIAME_DOWNLOAD_MODELS-FISH:BOOL=ON \
-DVIAME_DOWNLOAD_MODELS-ARCTIC-SEAL:BOOL=OFF \
-DVIAME_DOWNLOAD_MODELS-HABCAM:BOOL=OFF \
-DVIAME_DOWNLOAD_MODELS-MOUSS:BOOL=OFF

# Perform multi-threaded build
make -j$(nproc) || true
EOF

RUN <<EOF
# Below be krakens
# (V) (°,,,°) (V)   (V) (°,,,°) (V)   (V) (°,,,°) (V)
cd /viame/build

# HACK: Ensure invalid libsvm symlink isn't created
# Should be removed when this issue is fixed
rm install/lib/libsvm.so
cp install/lib/libsvm.so.2 install/lib/libsvm.so

# For local development keep the build directory for easier updates
mkdir -p /opt/noaa
ln -sf /viame/build/install /opt/noaa/viame

cd /
chown -R 1099:1099 /opt/noaa/viame


EOF

ENV PATH=/usr/local/cuda/bin:$PATH
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

RUN <<EOF
# https://www.docker.com/blog/introduction-to-heredocs-in-dockerfiles/
__doc__='

This is a variant of ``viame_gpu_sam.docker`` that builds using the local checkout

Build Instructions
------------------

The build instructions are meant to be run from the root of the VIAME repo on
your host machine. We will assume this is at ``$HOME/code/VIAME``. If this is
not the case modify the instructions to use the correct location.

.. code:: bash

    cd $HOME/code/VIAME

Then run the docker build 

.. code:: bash

    DOCKER_BUILDKIT=1 docker build --progress=plain \
        -t "viame:viame-gpu-local" \
        -f docker/viame_gpu_local.docker .


Now that the image has been built, we run it as a container, and mount the
local copy of the repo on ``/host-viame`` in the new container. In order to run
GPU algorithms it is important to increase the shared memory size.

.. code:: bash

    docker run --gpus=all \
        --shm-size=8g \
        --volume "$HOME/code/VIAME:/host-viame" \
        -it viame:viame-gpu-local \
        bash


Now that we are in a bash shell running inside the container, we update the
container's setup the container's copy of the repo to update itself to the
state on the host repo. To do this we first need to mark the host repo as safe:

.. code:: bash

    git config --global --add safe.directory /host-viame
    git config --global --add safe.directory /host-viame/.git

Now, you can navigate to the container repo and fetch the state of the host:

.. code:: bash

    cd /viame
    git fetch

Make sure you checkout the branch you are intersted in. The following code will
checkout whichever branch is current on the host.

.. code:: bash

    # hack, not sure why this step has errors, but removing and re-adding
    # origin seems to fix it. todo: clean this up
    git remote rm origin
    git remote add origin /host-viame/.git
    git fetch origin

    BRANCH_NAME=$(bash -c "cd /host-viame/ && git branch --show-current")
    echo "checking out BRANCH_NAME=$BRANCH_NAME"
    git fetch origin "$BRANCH_NAME"
    git checkout "$BRANCH_NAME" 

    git submodule update --init --recursive

This allows the developer to pull the local repo state into the container and
build it for faster iteration time. For example.

.. code:: bash

    cd /viame/build
    git pull
    make -j$(nproc)


In the installed directory test the algorithms using the VIAME CLI:

.. code:: bash

    cd /opt/noaa/viame/
    export PYTHONIOENCODING=utf-8
    source setup_viame.sh

    # Test a Huggingface detector
    cd /opt/noaa/viame/examples/object_detection
    cp /opt/noaa/viame/configs/pipelines/detector_huggingface_zeroshot.pipe detector_huggingface_zeroshot.pipe

    # Run the generic detector
    viame detector_huggingface_zeroshot.pipe \
          -s input:video_filename=input_image_list_small_set.txt \
          -s detector_writer:file_name=generic_detections.json \
          -s detector_writer:writer:type=coco


    # Use a specific prompt
    viame detector_huggingface_zeroshot.pipe \
          -s input:video_filename=input_image_list_small_set.txt \
          -s detector1:detector:ocv_windowed:detector:huggingface_zeroshot_detector:classes="[fish,starfish,coral]" \
          -s detector_writer:file_name=prompted_detections.json \
          -s detector_writer:writer:type=coco  

    # Copy data out of container for visualization
    cp -r ../example_imagery/small_example_image_set1/ /host-viame/example-images
    cp -r generic_detections.json /host-viame/example-images/generic_detections.json
    cp -r prompted_detections.json /host-viame/example-images/prompted_detections.json

    # ---

    # Train a MIT YOLO detector
    cd /opt/noaa/viame/examples/object_detector_training
    viame train \
      -i /opt/noaa/viame/examples/object_detector_training/training_data_mouss \
      -c /opt/noaa/viame/configs/pipelines/train_detector_mit_yolo_640.conf \
      --threshold 0.0

    # Grab a checkpoint
    CKPT_FPATH=$(python3 -c "if 1:
        import pathlib
        ckpt_dpath = pathlib.Path('/opt/noaa/viame/examples/object_detector_training/deep_training/train/viame-mit-yolo-detector/checkpoints/')
        checkpoints = sorted(ckpt_dpath.glob('*'))
        print(checkpoints[-1])
    ")
    echo "CKPT_FPATH=$CKPT_FPATH"

    # Move the weights and config into the cwd as a hack.
    cd /opt/noaa/viame/examples/object_detection
    cp "$CKPT_FPATH" demo-yolo-weights.ckpt
    cp /opt/noaa/viame/examples/object_detector_training/deep_training/train/viame-mit-yolo-detector/train_config.yaml train_config.yaml

    # Modify a template to create a pipeline file
    cp /opt/noaa/viame/configs/pipelines/templates/detector_mit_yolo.pipe demo_mit_yolo_detector.pipe
    sed -i 's|\[-MODEL-FILE-\]|demo-yolo-weights.ckpt|g' demo_mit_yolo_detector.pipe
    sed -i 's|\[-WINDOW-OPTION-\]|original_and_resized|g' demo_mit_yolo_detector.pipe

    # Run the YOLO detector inference
    export PYTHONIOENCODING=utf-8
    viame demo_mit_yolo_detector.pipe \
          -s input:video_filename=input_image_list_small_set.txt


It is also possible to directly symlink Python files from the host to the
correct system location for a development-install-like experience. E.g. to
develop on the mit_yolo_trainer run

.. code:: bash

    ln -sf /host-viame/plugins/pytorch/mit_yolo_trainer.py /opt/noaa/viame/lib/python3.10/site-packages/viame/arrows/pytorch/mit_yolo_trainer.py

    # Or more generally, just symlink files you are working on
    ln -sf /host-viame/plugins/pytorch/huggingface_zeroshot_detector.py /opt/noaa/viame/lib/python3.10/site-packages/viame/arrows/pytorch/huggingface_zeroshot_detector.py
    ln -sf /host-viame/plugins/pytorch/_util_kwimage.py /opt/noaa/viame/lib/python3.10/site-packages/viame/arrows/pytorch/_util_kwimage.py

    ln -sf /host-viame/configs/pipelines/detector_huggingface_zeroshot.pipe detector_huggingface_zeroshot.pipe


Manual Build Instructions
-------------------------

Sometimes building the image does not go smoothly, and the build itself needs
to be debugged. In this case, we can mount the base image and perform the build
steps manually.


.. code:: bash

    docker run --gpus=all \
        --shm-size=8g \
        --volume "$HOME/code/VIAME:/host-viame" \
        --name viame_gpu_local_manual_build_container \
        -it nvidia/cuda:12.4.1-cudnn-devel-ubuntu20.04 \
        bash

In the new container, we need to run a few extra commands to set things up
first

.. code:: bash

    apt-get update 
    apt-get install -y git 
    git config --global --add safe.directory /host-viame/.git

Now, run through the commands in the dockerfile manually.

'
EOF
