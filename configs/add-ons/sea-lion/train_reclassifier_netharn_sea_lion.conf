# =============================================================================
# Title: Training - Reclassifier NETHARN Sea Lion
#
# Description: Configuration file for VIAME pipeline
# =============================================================================

#  Groundtruth file extensions (txt, kw18, etc...). Note: this is indepedent of
#  the format that's stored in the file.
groundtruth_extensions = .csv

#  Algorithm to use for 'groundtruth_reader'.
#  Must be one of the following options:
#  	- habcam :: Reads habcam detection/ground truth files.
#  	- kw18 :: Detected object set reader using kw18 format.
groundtruth_reader:type = viame_csv

#  Dump possible input data formatting warnings to these files
data_warning_file = TRAINING_DATA_WARNINGS.txt
groundtruth_reader:viame_csv:warning_file = TRAINING_DATA_WARNINGS.txt

#  Can be either: "one_per_file" or "one_per_folder".
groundtruth_style = one_per_folder

#  Semicolon list of seperated image extensions to use in training, images
#  without this extension will not be included.
image_extensions = .jpg;.jpeg;.JPG;.JPEG;.tif;.tiff;.TIF;.TIFF;.png;.PNG;.sgi;.SGI;.bmp;.BMP;.pgm;.PGM

#  Semicolon list of seperated video extensions to use in training, videos
#  without this extension will not be included.
video_extensions = .mp4;.MP4;.mpg;.MPG;.mpeg;.MPEG;.avi;.AVI;.wmv;.WMV;.mov;.MOV;.webm;.WEBM;.ogg;.OGG

#  Pipeline to use to extract video frames if inputs are videos
relativepath video_extractor = filter_default.pipe

#  Percent [0.0, 1.0] of validation samples to use if no manual files specified.
default_percent_validation = 0.10

#  Number of validation frames to group together in one test burst
validation_burst_frame_count = 10

#  Augmentation pipeline.
#relativepath augmentation_pipeline = train_aug_hue_shifting_only.pipe

#  Augmentatation cache.
#augmentation_cache = augmented_images

#  Do not regenerate cache.
#regenerate_cache = true


#  Algorithm to use for 'detector_trainer'.
detector_trainer:type = netharn

block detector_trainer:netharn

  # Training a frame classifier not a detector
  mode = detection_refiner

  # Model identifier
  identifier = viame-detection-refiner

  # Network architecture
  arch = efficientnetv2s

  # Number of GPUs to use, -1 indicates all
  gpu_count = -1

  # Network perspective field size
  chip_width = 224

  # Max epoch count
  max_epochs = 100

  # Train only on images with ground truth
  gt_frames_only = false

  # Backbone file
  relativepath backbone = models/pytorch_efficientnet_s.pth

  # Pipeline template file.
  relativepath pipeline_template = templates/embedded_generic_netharn.pipe

  # Pivot area, asserts minimum size bound
  area_lower_bound = 500

  # Ignore entries near border
  border_exclude = 1

  # Max timeout in seconds
  timeout = 1209600

  # Image train batch size
  batch_size = auto

  # Training learning rate
  learning_rate = auto

  # Augmentation method
  augmentation = complex

  # Detection model for background sampling and box refinement
  relativepath detector_model = models/sea_lion_v3_cfrnn_two_class.zip

  # Maximum number of background samples per frame or random downsampling factor
  max_neg_per_frame = 100

  # Scale file for automatically determining scene scale
  relativepath scale_type_file = models/sea_lion_v3_target_scales.txt

endblock
