#  Groundtruth file extensions (txt, kw18, etc...). Note: this is indepedent of
#  the format that's stored in the file.
groundtruth_extensions = .csv

#  Algorithm to use for 'groundtruth_reader'.
#  Must be one of the following options:
#  	- habcam :: Reads habcam detection/ground truth files.
#  	- kw18 :: Detected object set reader using kw18 format.
#  	- viame_csv :: Detected object set reader using VIAME csv format.
groundtruth_reader:type = viame_csv

#  Dump possible input data formatting warnings to these files
data_warning_file = TRAINING_DATA_WARNINGS.txt
groundtruth_reader:viame_csv:warning_file = TRAINING_DATA_WARNINGS.txt

#  Can be either: "one_per_file" or "one_per_folder".
groundtruth_style = one_per_folder

#  Semicolon list of seperated image extensions to use in training, images
#  without this extension will not be included.
image_extensions = .jpg;.jpeg;.JPG;.JPEG;.tif;.tiff;.TIF;.TIFF;.png;.PNG;.sgi;.SGI;.bmp;.BMP;.pgm;.PGM

#  Semicolon list of seperated video extensions to use in training, videos
#  without this extension will not be included.
video_extensions = .mp4;.MP4;.mpg;.MPG;.mpeg;.MPEG;.avi;.AVI;.wmv;.WMV;.mov;.MOV;.webm;.WEBM;.ogg;.OGG

#  Pipeline to use to extract video frames if inputs are videos
relativepath video_extractor = filter_default.pipe

#  Percent [0.0, 1.0] of validation samples to use if no manual files specified.
default_percent_validation = 0.10

#  Number of validation frames to group together in one test burst
validation_burst_frame_count = 10

#  Augmentation pipeline.
#relativepath augmentation_pipeline = train_aug_hue_shifting_only.pipe

#  Augmentatation cache.
augmentation_cache = augmented_images

#  Do not regenerate cache.
regenerate_cache = true


#  Algorithm to use for 'detector_trainer'.
detector_trainer:type = ocv_windowed

block detector_trainer:ocv_windowed

  # Directory for all files used in training
  train_directory = deep_training

  # Windowing mode, can be disabled, maintain_ar, scale, chip, adaptive
  mode = original_and_resized

  # Resized chip width.
  chip_width = 640

  # Resized chip height.
  chip_height = 640

  # Adaptive size threshold for chipping
  chip_adaptive_thresh = 1600000

  # Don't train on chips with detections smaller than this
  min_train_box_length = 5

  # Uncomment to remove small detections instead of training on them
  #small_box_area = 290
  #small_action = remove

  # Image reader type
  image_reader:type = vxl

endblock

block detector_trainer:ocv_windowed:trainer

  # Trainer type
  type = litdet

  # Model architecture type (faster_rcnn, ssd, ssdlite, retinanet, fcos)
  litdet:model_type = faster_rcnn

  # Backbone architecture
  litdet:backbone = resnet50_fpn

  # Device to train on (auto, cpu, cuda, cuda:N)
  litdet:device = auto

  # Fine-tuning: use pretrained weights (true/false)
  litdet:fine_tune = true

  # Pretrained weights source: coco, imagenet, none, or path to weights file
  litdet:pretrained_weights = coco

  # Network perspective field size
  litdet:chip_width = 640

  # Path to seed model for continuing training
  litdet:seed_model =

  #  Pipeline template file.
  relativepath litdet:pipeline_template = templates/embedded_litdet.pipe

  # Image train batch size
  litdet:batch_size = 2

  # Maximum training epochs
  litdet:max_epochs = 100

  # Training learning rate
  litdet:learning_rate = 1e-3

  # Weight decay for optimizer
  litdet:weight_decay = 1e-6

  # Number of trainable backbone layers (0-5)
  litdet:trainable_backbone_layers = 3

  # Save top k checkpoints
  litdet:save_top_k = 1

  # Enable TensorBoard logging
  litdet:use_tensorboard = true

  # Run test evaluation after training
  litdet:run_test = true

endblock
