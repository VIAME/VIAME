# =============================================================================
# Title: Train Detector - SAM3 Segmentation
#
# Description: Configuration for training/fine-tuning SAM3 (Segment Anything
# Model 3) for segmentation tasks. Uses detection-level annotations with
# optional polygon masks. Input resolution: 1024px.
# =============================================================================

include common_train_detector.conf

#  Augmentation pipeline.
#relativepath augmentation_pipeline = train_aug_hue_shifting_only.pipe

#  Augmentatation cache.
#augmentation_cache = augmented_images

#  Do not regenerate cache.
#regenerate_cache = true


#  Algorithm to use for 'detector_trainer'.
detector_trainer:type = ocv_windowed

block detector_trainer:ocv_windowed

  # Directory for all files used in training
  train_directory = deep_training

  # Windowing mode, can be disabled, maintain_ar, scale, chip, adaptive
  mode = original_and_resized

  # Resized chip width.
  chip_width = 1024

  # Resized chip height.
  chip_height = 1024

  # Adaptive size threshold for chipping
  chip_adaptive_thresh = 2000000

  # Don't train on chips with detections smaller than this
  min_train_box_length = 5

  # Uncomment to remove small detections instead of training on them
  #small_box_area = 290
  #small_action = remove

  # Image reader type
  image_reader:type = vxl

endblock

block detector_trainer:ocv_windowed:trainer

  # Trainer type
  type = sam3

  # Model identifier for output files
  sam3:identifier = viame-sam3-segmentation

  # SAM model to fine-tune
  # Options: facebook/sam2.1-hiera-large, facebook/sam2.1-hiera-base,
  #          facebook/sam2.1-hiera-small, facebook/sam2.1-hiera-tiny
  sam3:sam_model_id = facebook/sam2.1-hiera-large

  # Number of GPUs to use, -1 indicates all
  sam3:gpu_count = -1

  # Network perspective field size
  sam3:chip_width = 1024
  sam3:chip_height = 1024

  # Max timeout in seconds (example = 604800, or one week)
  sam3:timeout = 604800

  # Image train batch size
  sam3:batch_size = 4

  # Maximum training epochs
  sam3:max_epochs = 50

  # Training learning rate
  sam3:learning_rate = 1e-5

  # Freeze image encoder (recommended for fine-tuning)
  sam3:freeze_image_encoder = true

  # Freeze prompt encoder (recommended for fine-tuning)
  sam3:freeze_prompt_encoder = true

  # Freeze memory encoder
  sam3:freeze_memory_encoder = false

  # Enable automatic mixed precision
  sam3:amp_enabled = true

  # Augmentation method (standard, complex, or none)
  sam3:augmentation = standard

  # Directory for final trained model output
  sam3:output_directory = category_models

  # Pipeline template file for deployment
  #relativepath sam3:pipeline_template = templates/embedded_sam3.pipe

endblock
