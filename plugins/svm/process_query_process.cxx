/* This file is part of VIAME, and is distributed under an OSI-approved *
 * BSD 3-Clause License. See either the root top-level LICENSE file or  *
 * https://github.com/VIAME/VIAME/blob/main/LICENSE.txt for details.    */

/**
 * \file
 * \brief Process query descriptors using IQR and SVM ranking
 */

#include "process_query_process.h"

#include <vital/vital_types.h>
#include <vital/types/descriptor.h>
#include <vital/types/descriptor_set.h>
#include <vital/logger/logger.h>

#include <svm.h>

#ifdef VIAME_ENABLE_CPPDB
#include <cppdb/frontend.h>
#endif

#include <algorithm>
#include <cmath>
#include <cstdint>
#include <cstdio>
#include <cstring>
#include <fstream>
#include <iostream>
#include <limits>
#include <queue>
#include <random>
#include <sstream>
#include <unordered_map>
#include <unordered_set>
#include <vector>

namespace viame
{

namespace svm
{

// Port traits for this process
create_port_trait( positive_descriptor_set, descriptor_set,
  "Positive exemplar descriptor set" );
create_port_trait( positive_exemplar_uids, string_vector,
  "Positive exemplar descriptor UIDs" );
create_port_trait( negative_descriptor_set, descriptor_set,
  "Negative exemplar descriptor set" );
create_port_trait( negative_exemplar_uids, string_vector,
  "Negative exemplar descriptor UIDs" );
create_port_trait( iqr_positive_uids, string_vector,
  "Positive sample UIDs from IQR feedback" );
create_port_trait( iqr_negative_uids, string_vector,
  "Negative sample UIDs from IQR feedback" );
create_port_trait( iqr_query_model, uchar_vector,
  "Input SVM model bytes for query" );
create_port_trait( result_uids, string_vector,
  "Result ranked descriptor UIDs in rank order" );
create_port_trait( result_scores, double_vector,
  "Result ranked descriptor scores in rank order" );
create_port_trait( feedback_uids, string_vector,
  "Feedback descriptor UIDs for active learning" );
create_port_trait( feedback_distances, double_vector,
  "Feedback descriptor distances from decision boundary" );
create_port_trait( feedback_scores, double_vector,
  "Feedback descriptor scores" );
create_port_trait( result_model, uchar_vector,
  "Trained SVM model bytes" );

// Config traits
create_config_trait( descriptor_index_file, std::string, "",
  "Path to the CSV file containing the searchable descriptor index (used if conn_str is empty)" );
create_config_trait( conn_str, std::string, "",
  "Database connection string (e.g., postgresql:host=localhost;user=postgres). "
  "If set, descriptors are loaded from the DESCRIPTOR table instead of CSV file." );
create_config_trait( pos_seed_neighbors, unsigned, "500",
  "Number of nearest neighbors to retrieve for each positive example" );
create_config_trait( query_return_size, unsigned, "500",
  "Number of ranked elements to return. 0 returns all." );
create_config_trait( svm_kernel_type, std::string, "histogram",
  "SVM kernel type: linear, poly, rbf, sigmoid, or histogram" );
create_config_trait( svm_c, double, "2.0",
  "SVM regularization parameter C" );
create_config_trait( svm_gamma, double, "0.0078125",
  "SVM gamma parameter for rbf/poly/sigmoid kernels" );
create_config_trait( nn_max_linear_search, unsigned, "50000",
  "Maximum number of descriptors for brute-force linear NN search. "
  "For larger indexes, approximate search with random sampling is used." );
create_config_trait( nn_sample_fraction, double, "0.1",
  "Fraction of index to sample when using approximate NN search (0.0-1.0). "
  "Only used when index size exceeds nn_max_linear_search." );
create_config_trait( autoneg_select_ratio, unsigned, "0",
  "Number of maximally distant descriptors to auto-select as negatives "
  "for each positive example when no negative examples are provided. "
  "Set to 0 (default) to disable auto-negatives. "
  "Set to 1+ to enable SVM training on the first query iteration." );

// LSH (Locality Sensitive Hashing) config traits for fast approximate NN search
create_config_trait( use_lsh_index, bool, "true",
  "Use LSH index for fast approximate nearest neighbor search. "
  "When enabled, requires ITQ model and hash code files. "
  "Falls back to brute-force if LSH files not found." );
create_config_trait( lsh_hash_codes_file, std::string, "database/ITQ/lsh_hash_codes.npy",
  "Path to numpy file containing LSH hash codes (uint8 array, N x bit_length). "
  "Generated by generate_nn_index.py." );
create_config_trait( lsh_hash_uids_file, std::string, "database/ITQ/lsh_hash_uids.txt",
  "Path to text file containing UIDs corresponding to hash codes (one per line). "
  "Generated by generate_nn_index.py." );
create_config_trait( itq_mean_vec_file, std::string, "database/ITQ/itq.model.b256_i100_r0.mean_vec.npy",
  "Path to numpy file containing ITQ mean vector for hash computation." );
create_config_trait( itq_rotation_file, std::string, "database/ITQ/itq.model.b256_i100_r0.rotation.npy",
  "Path to numpy file containing ITQ rotation matrix for hash computation." );
create_config_trait( lsh_bit_length, unsigned, "256",
  "Number of bits in LSH hash codes. Must match the trained ITQ model." );
create_config_trait( lsh_neighbor_multiplier, unsigned, "10",
  "Multiplier for LSH candidate retrieval. Retrieves k * multiplier candidates "
  "via hamming distance, then re-ranks with the configured distance method to get top k." );
create_config_trait( nn_distance_method, std::string, "euclidean",
  "Distance method for nearest neighbor re-ranking after LSH candidate retrieval. "
  "Options: 'euclidean', 'cosine', 'hik' (histogram intersection). "
  "Default is 'euclidean'." );
create_config_trait( use_platt_scaling, bool, "true",
  "Use custom Platt scaling with HIK distance for probability estimation. "
  "When true (default), uses custom Platt scaling with explicit HIK distance computation. "
  "When false, uses libsvm's built-in probability prediction." );
create_config_trait( force_exemplar_scores, bool, "false",
  "Force positive exemplars to score 1.0 and negative exemplars to score 0.0. "
  "When true, exemplar scores are overwritten after prediction. "
  "When false (default), exemplars receive their predicted scores." );

//--------------------------------------------------------------------------------
// Descriptor element for IQR
struct descriptor_element
{
  std::string uid;
  std::vector< double > vector;

  descriptor_element() = default;
  descriptor_element( const std::string& u, const std::vector< double >& v )
    : uid( u ), vector( v ) {}
};

//--------------------------------------------------------------------------------
// Simple numpy file reader for 1D and 2D arrays
// Supports float64 and uint8 types (sufficient for ITQ model and hash codes)
class numpy_array_reader
{
public:
  static bool read_float64_array( const std::string& filepath,
                                   std::vector< double >& out_data,
                                   std::vector< size_t >& out_shape )
  {
    std::ifstream file( filepath, std::ios::binary );
    if( !file.is_open() )
    {
      return false;
    }

    // Read numpy header
    char magic[6];
    file.read( magic, 6 );
    if( magic[0] != '\x93' || std::string( magic + 1, 5 ) != "NUMPY" )
    {
      return false;
    }

    uint8_t major_version, minor_version;
    file.read( reinterpret_cast< char* >( &major_version ), 1 );
    file.read( reinterpret_cast< char* >( &minor_version ), 1 );

    uint32_t header_len;
    if( major_version == 1 )
    {
      uint16_t len16;
      file.read( reinterpret_cast< char* >( &len16 ), 2 );
      header_len = len16;
    }
    else
    {
      file.read( reinterpret_cast< char* >( &header_len ), 4 );
    }

    std::string header( header_len, '\0' );
    file.read( &header[0], header_len );

    // Parse shape from header (simple parsing for common cases)
    out_shape.clear();
    size_t shape_start = header.find( "\'shape\': (" );
    if( shape_start != std::string::npos )
    {
      shape_start += 10;
      size_t shape_end = header.find( ")", shape_start );
      std::string shape_str = header.substr( shape_start, shape_end - shape_start );

      std::stringstream ss( shape_str );
      std::string token;
      while( std::getline( ss, token, ',' ) )
      {
        token.erase( 0, token.find_first_not_of( " " ) );
        token.erase( token.find_last_not_of( " " ) + 1 );
        if( !token.empty() )
        {
          out_shape.push_back( std::stoull( token ) );
        }
      }
    }

    // Calculate total elements
    size_t total_elements = 1;
    for( size_t dim : out_shape )
    {
      total_elements *= dim;
    }

    // Read data
    out_data.resize( total_elements );
    file.read( reinterpret_cast< char* >( out_data.data() ),
               total_elements * sizeof( double ) );

    return file.good() || file.eof();
  }

  static bool read_uint8_array( const std::string& filepath,
                                 std::vector< uint8_t >& out_data,
                                 std::vector< size_t >& out_shape )
  {
    std::ifstream file( filepath, std::ios::binary );
    if( !file.is_open() )
    {
      return false;
    }

    // Read numpy header
    char magic[6];
    file.read( magic, 6 );
    if( magic[0] != '\x93' || std::string( magic + 1, 5 ) != "NUMPY" )
    {
      return false;
    }

    uint8_t major_version, minor_version;
    file.read( reinterpret_cast< char* >( &major_version ), 1 );
    file.read( reinterpret_cast< char* >( &minor_version ), 1 );

    uint32_t header_len;
    if( major_version == 1 )
    {
      uint16_t len16;
      file.read( reinterpret_cast< char* >( &len16 ), 2 );
      header_len = len16;
    }
    else
    {
      file.read( reinterpret_cast< char* >( &header_len ), 4 );
    }

    std::string header( header_len, '\0' );
    file.read( &header[0], header_len );

    // Parse shape from header
    out_shape.clear();
    size_t shape_start = header.find( "\'shape\': (" );
    if( shape_start != std::string::npos )
    {
      shape_start += 10;
      size_t shape_end = header.find( ")", shape_start );
      std::string shape_str = header.substr( shape_start, shape_end - shape_start );

      std::stringstream ss( shape_str );
      std::string token;
      while( std::getline( ss, token, ',' ) )
      {
        token.erase( 0, token.find_first_not_of( " " ) );
        token.erase( token.find_last_not_of( " " ) + 1 );
        if( !token.empty() )
        {
          out_shape.push_back( std::stoull( token ) );
        }
      }
    }

    // Calculate total elements
    size_t total_elements = 1;
    for( size_t dim : out_shape )
    {
      total_elements *= dim;
    }

    // Read data
    out_data.resize( total_elements );
    file.read( reinterpret_cast< char* >( out_data.data() ), total_elements );

    return file.good() || file.eof();
  }
};

//--------------------------------------------------------------------------------
// LSH Index class for fast approximate nearest neighbor search
// Uses ITQ (Iterative Quantization) for hash code computation
class lsh_index
{
public:
  lsh_index() : m_bit_length( 0 ), m_num_descriptors( 0 ) {}

  bool load( const std::string& hash_codes_file,
             const std::string& hash_uids_file,
             const std::string& mean_vec_file,
             const std::string& rotation_file,
             unsigned bit_length )
  {
    m_bit_length = bit_length;

    // Load ITQ mean vector
    std::vector< size_t > mean_shape;
    if( !numpy_array_reader::read_float64_array( mean_vec_file, m_mean_vec, mean_shape ) )
    {
      return false;
    }

    // Load ITQ rotation matrix
    std::vector< size_t > rotation_shape;
    if( !numpy_array_reader::read_float64_array( rotation_file, m_rotation, rotation_shape ) )
    {
      return false;
    }

    if( rotation_shape.size() != 2 )
    {
      return false;
    }
    m_feature_dim = rotation_shape[0];
    m_rotation_cols = rotation_shape[1];

    // Load hash codes
    std::vector< size_t > hash_shape;
    if( !numpy_array_reader::read_uint8_array( hash_codes_file, m_hash_codes, hash_shape ) )
    {
      return false;
    }

    if( hash_shape.size() != 2 || hash_shape[1] != bit_length )
    {
      return false;
    }
    m_num_descriptors = hash_shape[0];

    // Load UIDs
    std::ifstream uid_file( hash_uids_file );
    if( !uid_file.is_open() )
    {
      return false;
    }

    m_uids.clear();
    m_uids.reserve( m_num_descriptors );
    std::string line;
    while( std::getline( uid_file, line ) )
    {
      if( !line.empty() )
      {
        // Trim whitespace
        line.erase( 0, line.find_first_not_of( " \t\r\n" ) );
        line.erase( line.find_last_not_of( " \t\r\n" ) + 1 );
        if( !line.empty() )
        {
          m_uids.push_back( line );
        }
      }
    }

    if( m_uids.size() != m_num_descriptors )
    {
      return false;
    }

    // Build UID to index map for fast lookups
    m_uid_to_index.clear();
    for( size_t i = 0; i < m_uids.size(); ++i )
    {
      m_uid_to_index[m_uids[i]] = i;
    }

    return true;
  }

  bool is_loaded() const
  {
    return m_num_descriptors > 0 && !m_hash_codes.empty();
  }

  // Compute hash code for a descriptor using ITQ
  std::vector< uint8_t > compute_hash( const std::vector< double >& descriptor ) const
  {
    if( descriptor.size() != m_feature_dim )
    {
      return {};
    }

    // Center the descriptor
    std::vector< double > centered( m_feature_dim );
    for( size_t i = 0; i < m_feature_dim; ++i )
    {
      centered[i] = descriptor[i] - m_mean_vec[i];
    }

    // Project using rotation matrix: z = centered @ rotation
    std::vector< double > projected( m_rotation_cols, 0.0 );
    for( size_t j = 0; j < m_rotation_cols; ++j )
    {
      for( size_t i = 0; i < m_feature_dim; ++i )
      {
        projected[j] += centered[i] * m_rotation[i * m_rotation_cols + j];
      }
    }

    // Quantize to binary
    std::vector< uint8_t > hash( m_bit_length );
    for( size_t i = 0; i < m_bit_length && i < projected.size(); ++i )
    {
      hash[i] = ( projected[i] >= 0 ) ? 1 : 0;
    }

    return hash;
  }

  // Compute hamming distance between two hash codes
  static unsigned hamming_distance( const std::vector< uint8_t >& a,
                                     const std::vector< uint8_t >& b )
  {
    unsigned dist = 0;
    size_t len = std::min( a.size(), b.size() );
    for( size_t i = 0; i < len; ++i )
    {
      if( a[i] != b[i] )
      {
        ++dist;
      }
    }
    return dist;
  }

  // Find k nearest neighbors using LSH (hamming distance)
  // Returns (uid, hamming_distance) pairs sorted by distance
  std::vector< std::pair< std::string, unsigned > > find_neighbors_lsh(
    const std::vector< double >& query_descriptor,
    size_t k ) const
  {
    if( !is_loaded() )
    {
      return {};
    }

    // Compute query hash
    std::vector< uint8_t > query_hash = compute_hash( query_descriptor );
    if( query_hash.empty() )
    {
      return {};
    }

    // Find k nearest by hamming distance using a max-heap
    using pair_type = std::pair< unsigned, size_t >; // (distance, index)
    std::priority_queue< pair_type > pq;

    for( size_t i = 0; i < m_num_descriptors; ++i )
    {
      // Get hash code for this descriptor
      std::vector< uint8_t > hash( m_bit_length );
      for( size_t j = 0; j < m_bit_length; ++j )
      {
        hash[j] = m_hash_codes[i * m_bit_length + j];
      }

      unsigned dist = hamming_distance( query_hash, hash );

      if( pq.size() < k )
      {
        pq.push( { dist, i } );
      }
      else if( dist < pq.top().first )
      {
        pq.pop();
        pq.push( { dist, i } );
      }
    }

    // Convert to result vector
    std::vector< std::pair< std::string, unsigned > > results;
    results.reserve( pq.size() );
    while( !pq.empty() )
    {
      results.emplace_back( m_uids[pq.top().second], pq.top().first );
      pq.pop();
    }

    // Reverse to get closest first
    std::reverse( results.begin(), results.end() );
    return results;
  }

  // Get UID by index
  const std::string& get_uid( size_t index ) const
  {
    return m_uids[index];
  }

  // Check if UID exists in index
  bool has_uid( const std::string& uid ) const
  {
    return m_uid_to_index.find( uid ) != m_uid_to_index.end();
  }

  size_t size() const { return m_num_descriptors; }
  unsigned bit_length() const { return m_bit_length; }

private:
  unsigned m_bit_length;
  size_t m_num_descriptors;
  size_t m_feature_dim;
  size_t m_rotation_cols;

  std::vector< double > m_mean_vec;
  std::vector< double > m_rotation;
  std::vector< uint8_t > m_hash_codes;
  std::vector< std::string > m_uids;
  std::unordered_map< std::string, size_t > m_uid_to_index;
};

//--------------------------------------------------------------------------------
// IQR Session class - manages the interactive query refinement state
class iqr_session
{
public:
  iqr_session( unsigned pos_seed_neighbors )
    : m_pos_seed_neighbors( pos_seed_neighbors )
    , m_svm_model( nullptr )
  {
    // Suppress libSVM output
    svm_set_print_string_function( []( const char* ) {} );
  }

  ~iqr_session()
  {
    free_model();
  }

  void reset()
  {
    m_positive_descriptors.clear();
    m_negative_descriptors.clear();
    m_working_index.clear();
    free_model();
  }

  void adjudicate( const std::vector< descriptor_element >& positives,
                   const std::vector< descriptor_element >& negatives = {} )
  {
    for( const auto& desc : positives )
    {
      m_positive_descriptors[desc.uid] = desc;
    }
    for( const auto& desc : negatives )
    {
      m_negative_descriptors[desc.uid] = desc;
    }
  }

  void update_working_index(
    const std::unordered_map< std::string, std::vector< double > >& full_index )
  {
    // Add all positive and negative descriptors to working index
    for( const auto& p : m_positive_descriptors )
    {
      m_working_index[p.first] = p.second;
    }
    for( const auto& n : m_negative_descriptors )
    {
      m_working_index[n.first] = n.second;
    }

    // For each positive, find nearest neighbors and add to working index
    for( const auto& pos : m_positive_descriptors )
    {
      auto neighbors = find_nearest_neighbors(
        pos.second.vector, full_index, m_pos_seed_neighbors );

      for( const auto& neighbor : neighbors )
      {
        if( m_working_index.find( neighbor.first ) == m_working_index.end() )
        {
          m_working_index[neighbor.first] = descriptor_element(
            neighbor.first, full_index.at( neighbor.first ) );
        }
      }
    }
  }

  bool refine()
  {
    if( m_positive_descriptors.empty() )
    {
      return false;
    }

    // Free existing model
    free_model();

    // Auto-select negatives if none provided
    std::vector< descriptor_element > auto_negatives;
    if( m_negative_descriptors.empty() && m_autoneg_select_ratio > 0 )
    {
      auto_negatives = select_auto_negatives();
    }

    // If still no negatives (manual or auto), return true but no model
    if( m_negative_descriptors.empty() && auto_negatives.empty() )
    {
      return true;
    }

    // Build SVM training data
    size_t n_pos = m_positive_descriptors.size();
    size_t n_neg = m_negative_descriptors.size() + auto_negatives.size();
    size_t n_total = n_pos + n_neg;

    if( n_total < 2 )
    {
      return false;
    }

    // Allocate SVM problem
    svm_problem prob;
    prob.l = static_cast< int >( n_total );
    prob.y = new double[n_total];
    prob.x = new svm_node*[n_total];

    // Fill in positive samples (label +1)
    size_t idx = 0;
    for( const auto& p : m_positive_descriptors )
    {
      prob.y[idx] = 1.0;
      prob.x[idx] = allocate_svm_nodes( p.second.vector );
      ++idx;
    }

    // Fill in negative samples (label -1)
    for( const auto& n : m_negative_descriptors )
    {
      prob.y[idx] = -1.0;
      prob.x[idx] = allocate_svm_nodes( n.second.vector );
      ++idx;
    }

    // Fill in auto-selected negative samples (label -1)
    for( const auto& n : auto_negatives )
    {
      prob.y[idx] = -1.0;
      prob.x[idx] = allocate_svm_nodes( n.vector );
      ++idx;
    }

    // Set SVM parameters
    svm_parameter param;
    std::memset( &param, 0, sizeof( param ) );
    param.svm_type = C_SVC;
    param.kernel_type = m_kernel_type;
    param.degree = 3;
    param.gamma = m_gamma;
    param.coef0 = 0;
    param.cache_size = 200;
    param.eps = 0.001;
    param.C = m_c;
    param.nu = 0.5;
    param.p = 0.1;
    param.shrinking = 1;
    param.probability = 1;

    // Class weighting to handle imbalanced pos/neg samples
    // Weight for positive class = max(1.0, num_neg / num_pos)
    int weight_labels[2] = { 1, -1 };
    double weights[2] = {
      std::max( 1.0, static_cast< double >( n_neg ) / n_pos ),
      1.0
    };
    param.nr_weight = 2;
    param.weight_label = weight_labels;
    param.weight = weights;

    // Check parameters
    const char* error = svm_check_parameter( &prob, &param );
    if( error )
    {
      // Clean up and return
      for( size_t i = 0; i < n_total; ++i )
      {
        delete[] prob.x[i];
      }
      delete[] prob.x;
      delete[] prob.y;
      return false;
    }

    // Train model
    m_svm_model = svm_train( &prob, &param );

    // Clean up training data
    for( size_t i = 0; i < n_total; ++i )
    {
      delete[] prob.x[i];
    }
    delete[] prob.x;
    delete[] prob.y;

    // Validate model is usable (has all required fields)
    if( m_svm_model && !is_model_valid() )
    {
      free_model();
    }

    return m_svm_model != nullptr;
  }

  // Get ordered results from working index
  std::vector< std::pair< std::string, double > > ordered_results()
  {
    std::vector< std::pair< std::string, double > > results;

    // First, score ALL items in working index
    for( const auto& entry : m_working_index )
    {
      double score = predict_score( entry.second.vector );
      results.emplace_back( entry.first, score );
    }

    // Check if probabilities need to be inverted
    // If positive exemplars have lower average probability than overall average,
    // the SVM labels may be flipped
    if( is_model_valid() && !m_positive_descriptors.empty() && !results.empty() )
    {
      double pos_prob_sum = 0.0;
      for( const auto& p : m_positive_descriptors )
      {
        pos_prob_sum += predict_score( p.second.vector );
      }
      double pos_avg = pos_prob_sum / m_positive_descriptors.size();

      double all_prob_sum = 0.0;
      for( const auto& r : results )
      {
        all_prob_sum += r.second;
      }
      double all_avg = all_prob_sum / results.size();

      // If positive examples have lower average probability, invert all scores
      if( pos_avg < all_avg )
      {
        for( auto& r : results )
        {
          r.second = 1.0 - r.second;
        }
        m_invert_probabilities = true;
      }
      else
      {
        m_invert_probabilities = false;
      }
    }

    // Optionally force positive exemplars to score 1.0 and negative to 0.0
    // This is done AFTER the inversion check
    if( m_force_exemplar_scores )
    {
      for( auto& r : results )
      {
        if( m_positive_descriptors.find( r.first ) != m_positive_descriptors.end() )
        {
          r.second = 1.0;
        }
        else if( m_negative_descriptors.find( r.first ) != m_negative_descriptors.end() )
        {
          r.second = 0.0;
        }
      }
    }

    // Sort by score descending
    std::sort( results.begin(), results.end(),
      []( const auto& a, const auto& b ) { return a.second > b.second; } );

    return results;
  }

  // Get feedback descriptors (closest to decision boundary, or by similarity if no model)
  std::vector< std::pair< std::string, double > > ordered_feedback() const
  {
    bool has_valid_model = is_model_valid();

    std::vector< std::pair< std::string, double > > feedback;

    for( const auto& entry : m_working_index )
    {
      if( has_valid_model )
      {
        // With SVM model: use distance to decision boundary
        double distance = predict_distance( entry.second.vector );
        feedback.emplace_back( entry.first, std::abs( distance ) );
      }
      else
      {
        // Without SVM model: use similarity to positive exemplars
        // Lower similarity = more uncertain = better feedback candidate
        double similarity = compute_positive_similarity( entry.second.vector );
        feedback.emplace_back( entry.first, similarity );
      }
    }

    if( has_valid_model )
    {
      // Sort by absolute distance ascending (closest to boundary first)
      std::sort( feedback.begin(), feedback.end(),
        []( const auto& a, const auto& b ) { return a.second < b.second; } );
    }
    else
    {
      // Sort by similarity - medium similarity samples are best for feedback
      // (not too similar to positives, not too dissimilar)
      // Sort descending so highest similarity first, then take from middle
      std::sort( feedback.begin(), feedback.end(),
        []( const auto& a, const auto& b ) { return a.second > b.second; } );

      // Reorder to prioritize samples near the median similarity
      if( feedback.size() > 2 )
      {
        size_t mid = feedback.size() / 2;
        std::vector< std::pair< std::string, double > > reordered;
        reordered.reserve( feedback.size() );

        // Interleave from middle outward
        size_t left = mid;
        size_t right = mid + 1;
        bool pick_left = true;

        while( reordered.size() < feedback.size() )
        {
          if( pick_left && left > 0 )
          {
            --left;
            reordered.push_back( feedback[left] );
          }
          else if( !pick_left && right < feedback.size() )
          {
            reordered.push_back( feedback[right] );
            ++right;
          }
          else if( left > 0 )
          {
            --left;
            reordered.push_back( feedback[left] );
          }
          else if( right < feedback.size() )
          {
            reordered.push_back( feedback[right] );
            ++right;
          }
          else
          {
            // Safety break to prevent infinite loop
            break;
          }
          pick_left = !pick_left;
        }
        feedback = std::move( reordered );
      }
    }

    return feedback;
  }

  // Get SVM model as bytes
  std::vector< unsigned char > get_model_bytes() const
  {
    if( !is_model_valid() )
    {
      return {};
    }

    // Save to temporary file
    const char* tmp_file = "tmp_svm_model.bin";
    if( svm_save_model( tmp_file, m_svm_model ) != 0 )
    {
      return {};
    }

    // Read file contents
    std::ifstream file( tmp_file, std::ios::binary | std::ios::ate );
    if( !file.is_open() )
    {
      std::remove( tmp_file );
      return {};
    }

    std::streamsize size = file.tellg();
    file.seekg( 0, std::ios::beg );

    std::vector< unsigned char > bytes( size );
    file.read( reinterpret_cast< char* >( bytes.data() ), size );
    file.close();

    std::remove( tmp_file );
    return bytes;
  }

  // Load SVM model from bytes
  bool load_model_from_bytes( const std::vector< unsigned char >& bytes )
  {
    if( bytes.empty() )
    {
      return false;
    }

    free_model();

    // Write to temporary file
    const char* tmp_file = "tmp_svm_model_load.bin";
    std::ofstream file( tmp_file, std::ios::binary );
    if( !file.is_open() )
    {
      return false;
    }
    file.write( reinterpret_cast< const char* >( bytes.data() ), bytes.size() );
    file.close();

    // Load model
    m_svm_model = svm_load_model( tmp_file );
    std::remove( tmp_file );

    return m_svm_model != nullptr;
  }

  void set_kernel_type( const std::string& type )
  {
    if( type == "linear" ) m_kernel_type = LINEAR;
    else if( type == "poly" ) m_kernel_type = POLY;
    else if( type == "rbf" ) m_kernel_type = RBF;
    else if( type == "sigmoid" ) m_kernel_type = SIGMOID;
    else if( type == "histogram" ) m_kernel_type = HISTOGRAM;
    else m_kernel_type = HISTOGRAM;
  }

  void set_c( double c ) { m_c = c; }
  void set_gamma( double gamma ) { m_gamma = gamma; }
  void set_nn_max_linear_search( unsigned max ) { m_nn_max_linear_search = max; }
  void set_nn_sample_fraction( double fraction ) { m_nn_sample_fraction = fraction; }
  void set_autoneg_select_ratio( unsigned ratio ) { m_autoneg_select_ratio = ratio; }

  void set_full_index_ref(
    const std::unordered_map< std::string, std::vector< double > >* index )
  {
    m_full_index_ref = index;
  }

  void set_lsh_index_ref( const lsh_index* index ) { m_lsh_index_ref = index; }
  void set_lsh_neighbor_multiplier( unsigned mult ) { m_lsh_neighbor_multiplier = mult; }
  void set_nn_distance_method( const std::string& method ) { m_nn_distance_method = method; }
  void set_use_platt_scaling( bool use_platt ) { m_use_platt_scaling = use_platt; }
  void set_force_exemplar_scores( bool force ) { m_force_exemplar_scores = force; }

private:
  void free_model()
  {
    if( m_svm_model )
    {
      svm_free_and_destroy_model( &m_svm_model );
      m_svm_model = nullptr;
    }
  }

  // Check if SVM model is valid and safe to use
  bool is_model_valid() const
  {
    if( !m_svm_model )
    {
      return false;
    }

    if( m_svm_model->l <= 0 ||
        m_svm_model->SV == nullptr ||
        m_svm_model->sv_coef == nullptr ||
        m_svm_model->rho == nullptr ||
        m_svm_model->nSV == nullptr ||
        m_svm_model->nr_class < 2 )
    {
      return false;
    }

    // Check sv_coef sub-arrays
    for( int i = 0; i < m_svm_model->nr_class - 1; ++i )
    {
      if( m_svm_model->sv_coef[i] == nullptr )
      {
        return false;
      }
    }

    return true;
  }

  svm_node* allocate_svm_nodes( const std::vector< double >& vec ) const
  {
    svm_node* nodes = new svm_node[vec.size() + 1];
    for( size_t i = 0; i < vec.size(); ++i )
    {
      nodes[i].index = static_cast< int >( i + 1 );
      nodes[i].value = vec[i];
    }
    nodes[vec.size()].index = -1;
    nodes[vec.size()].value = 0;
    return nodes;
  }

  // Custom Platt scaling using histogram intersection kernel.
  // Computes: margin = sum(sv_coef[i] * HIK_kernel(SV[i], test_vec))
  // where HIK_kernel = sum(min(a[i], b[i])) is the intersection (similarity)
  // Then applies: prob = 1.0 / (1.0 + exp((margin - rho) * probA + probB))
  double predict_score_platt( const std::vector< double >& vec ) const
  {
    if( !is_model_valid() )
    {
      return compute_positive_similarity( vec );
    }

    // Safety checks
    if( !m_svm_model->SV || !m_svm_model->sv_coef || !m_svm_model->rho )
    {
      return compute_positive_similarity( vec );
    }

    // Get model parameters
    int num_svs = m_svm_model->l;
    if( num_svs <= 0 )
    {
      return compute_positive_similarity( vec );
    }

    double rho = m_svm_model->rho[0];
    double probA = m_svm_model->probA ? m_svm_model->probA[0] : 0.0;
    double probB = m_svm_model->probB ? m_svm_model->probB[0] : 0.0;

    // Compute margin using histogram intersection distance
    // margin = sum(sv_coef[i] * HIK_distance(SV[i], vec))
    double margin = 0.0;
    size_t vec_dim = vec.size();

    for( int i = 0; i < num_svs; ++i )
    {
      if( !m_svm_model->SV[i] || !m_svm_model->sv_coef[0] )
      {
        continue;
      }

      // Pre-allocate support vector with zeros to match input dimension
      std::vector< double > sv( vec_dim, 0.0 );

      // Extract non-zero elements from sparse SV representation
      for( int j = 0; m_svm_model->SV[i][j].index != -1; ++j )
      {
        int idx = m_svm_model->SV[i][j].index - 1;  // libsvm uses 1-based indexing
        if( idx >= 0 && idx < static_cast< int >( vec_dim ) )
        {
          sv[idx] = m_svm_model->SV[i][j].value;
        }
      }

      // Compute histogram intersection KERNEL (similarity), not distance
      // HIK kernel = intersection_sum, distance = 1 - intersection_sum
      // For SVM margin computation, we need the kernel value
      double kernel_value = 1.0 - histogram_intersection_distance( sv, vec );

      // sv_coef is alpha * y for each SV (for binary classification, sv_coef[0])
      margin += m_svm_model->sv_coef[0][i] * kernel_value;
    }

    // Apply Platt scaling formula
    double prob = 1.0 / ( 1.0 + std::exp( ( margin - rho ) * probA + probB ) );

    return prob;
  }

  // Use libsvm's built-in probability prediction
  double predict_score_libsvm( const std::vector< double >& vec ) const
  {
    if( !is_model_valid() )
    {
      return compute_positive_similarity( vec );
    }

    svm_node* nodes = allocate_svm_nodes( vec );

    double prob_estimates[2];
    svm_predict_probability( m_svm_model, nodes, prob_estimates );

    delete[] nodes;

    // Get label order
    int labels[2];
    svm_get_labels( m_svm_model, labels );

    // Return probability for positive class (label +1)
    return ( labels[0] == 1 ) ? prob_estimates[0] : prob_estimates[1];
  }

  double predict_score( const std::vector< double >& vec ) const
  {
    if( m_use_platt_scaling )
    {
      // Use custom Platt scaling with HIK distance
      return predict_score_platt( vec );
    }
    else
    {
      // Use libsvm's built-in probability prediction with HIK kernel
      return predict_score_libsvm( vec );
    }
  }

  double predict_distance( const std::vector< double >& vec ) const
  {
    if( !is_model_valid() )
    {
      return 0.0;
    }

    svm_node* nodes = allocate_svm_nodes( vec );

    double dec_values[1];
    svm_predict_values( m_svm_model, nodes, dec_values );

    delete[] nodes;
    return dec_values[0];
  }

  double compute_positive_similarity( const std::vector< double >& vec ) const
  {
    if( m_positive_descriptors.empty() )
    {
      return 0.0;
    }

    // Compute mean cosine similarity to positive descriptors
    // Cosine similarity is better for unnormalized feature vectors (like CNN features)
    // Returns value in [0, 1] where 1 = identical direction
    double total_similarity = 0.0;
    for( const auto& p : m_positive_descriptors )
    {
      double dist = cosine_distance( vec, p.second.vector );
      // Cosine distance is in [0, 1], so similarity = 1 - distance
      total_similarity += ( 1.0 - dist );
    }

    return total_similarity / m_positive_descriptors.size();
  }

  // Auto-select negative examples by finding the most distant descriptors
  // from each positive example using histogram intersection distance.
  // Auto-negatives are selected from the FULL descriptor index (like SMQTK)
  // to find the most distant descriptors in the entire dataset.
  std::vector< descriptor_element > select_auto_negatives() const
  {
    if( !m_full_index_ref || m_full_index_ref->empty() ||
        m_positive_descriptors.empty() || m_autoneg_select_ratio == 0 )
    {
      return {};
    }

    std::unordered_set< std::string > selected_uids;
    std::vector< descriptor_element > auto_negatives;

    // For each positive, find the most distant descriptors in the FULL index
    // (matching SMQTK behavior which selects from the entire descriptor cache)
    for( const auto& pos : m_positive_descriptors )
    {
      // Priority queue to track most distant descriptors (min-heap by distance)
      // We use min-heap so we can efficiently maintain top-k most distant
      using pair_type = std::pair< double, std::string >;
      std::priority_queue< pair_type, std::vector< pair_type >,
        std::greater< pair_type > > pq;

      for( const auto& entry : *m_full_index_ref )
      {
        // Skip if already a positive or negative or already selected
        if( m_positive_descriptors.find( entry.first ) !=
            m_positive_descriptors.end() )
        {
          continue;
        }
        if( m_negative_descriptors.find( entry.first ) !=
            m_negative_descriptors.end() )
        {
          continue;
        }
        if( selected_uids.find( entry.first ) != selected_uids.end() )
        {
          continue;
        }

        // Use histogram intersection distance
        double dist = histogram_intersection_distance(
          pos.second.vector, entry.second );

        if( pq.size() < m_autoneg_select_ratio )
        {
          pq.push( { dist, entry.first } );
        }
        else if( dist > pq.top().first )
        {
          pq.pop();
          pq.push( { dist, entry.first } );
        }
      }

      // Add most distant descriptors as auto-negatives
      while( !pq.empty() )
      {
        const auto& uid = pq.top().second;
        if( selected_uids.find( uid ) == selected_uids.end() )
        {
          selected_uids.insert( uid );
          auto_negatives.emplace_back( uid, m_full_index_ref->at( uid ) );
        }
        pq.pop();
      }
    }

    return auto_negatives;
  }

  static double euclidean_distance( const std::vector< double >& a,
                                    const std::vector< double >& b )
  {
    if( a.size() != b.size() )
    {
      return std::numeric_limits< double >::max();
    }

    double sum = 0.0;
    for( size_t i = 0; i < a.size(); ++i )
    {
      double diff = a[i] - b[i];
      sum += diff * diff;
    }
    return std::sqrt( sum );
  }

  // Cosine distance
  // Returns value between 0.0 (identical) and 1.0 (orthogonal) for positive vectors
  static double cosine_distance( const std::vector< double >& a,
                                 const std::vector< double >& b )
  {
    if( a.size() != b.size() || a.empty() )
    {
      return 1.0;
    }

    double dot = 0.0, norm_a = 0.0, norm_b = 0.0;
    for( size_t i = 0; i < a.size(); ++i )
    {
      dot += a[i] * b[i];
      norm_a += a[i] * a[i];
      norm_b += b[i] * b[i];
    }

    if( norm_a == 0.0 || norm_b == 0.0 )
    {
      return 1.0;
    }

    double similarity = dot / ( std::sqrt( norm_a ) * std::sqrt( norm_b ) );
    // Clamp to [-1, 1] for numerical stability
    similarity = std::max( -1.0, std::min( 1.0, similarity ) );
    // For positive vectors, convert similarity to distance in [0, 1]
    return std::acos( similarity ) / M_PI;
  }

  // Histogram intersection distance
  // Returns value between 0.0 (full intersection) and 1.0 (no intersection)
  // Formula: 1.0 - sum(min(a[i], b[i])) = 1.0 - ((a + b - |a - b|) / 2).sum()
  static double histogram_intersection_distance( const std::vector< double >& a,
                                                  const std::vector< double >& b )
  {
    if( a.size() != b.size() )
    {
      return 1.0;  // No intersection if sizes differ
    }

    double intersection_sum = 0.0;
    for( size_t i = 0; i < a.size(); ++i )
    {
      // Non-branching min: (a + b - |a - b|) / 2
      intersection_sum += ( a[i] + b[i] - std::abs( a[i] - b[i] ) ) * 0.5;
    }

    return 1.0 - intersection_sum;
  }

  // Compute distance using the configured method
  double compute_distance( const std::vector< double >& a,
                           const std::vector< double >& b ) const
  {
    if( m_nn_distance_method == "euclidean" )
    {
      return euclidean_distance( a, b );
    }
    else if( m_nn_distance_method == "cosine" )
    {
      return cosine_distance( a, b );
    }
    else // "hik" or default
    {
      return histogram_intersection_distance( a, b );
    }
  }

  std::vector< std::pair< std::string, double > > find_nearest_neighbors(
    const std::vector< double >& query,
    const std::unordered_map< std::string, std::vector< double > >& index,
    size_t k ) const
  {
    // Priority queue for k nearest neighbors (max heap by distance)
    using pair_type = std::pair< double, std::string >;
    std::priority_queue< pair_type > pq;

    // Try LSH-based search first for fast approximate nearest neighbors
    if( m_lsh_index_ref && m_lsh_index_ref->is_loaded() )
    {
      // Use LSH to get candidates, then re-rank with histogram intersection
      size_t lsh_k = k * m_lsh_neighbor_multiplier;
      auto lsh_candidates = m_lsh_index_ref->find_neighbors_lsh( query, lsh_k );

      // Re-rank candidates using histogram intersection distance
      for( const auto& candidate : lsh_candidates )
      {
        const std::string& uid = candidate.first;
        auto it = index.find( uid );
        if( it == index.end() )
        {
          continue;
        }

        double dist = compute_distance( query, it->second );

        if( pq.size() < k )
        {
          pq.push( { dist, uid } );
        }
        else if( dist < pq.top().first )
        {
          pq.pop();
          pq.push( { dist, uid } );
        }
      }
    }
    else
    {
      // Fall back to brute-force or random sampling
      bool use_approximate = ( index.size() > m_nn_max_linear_search );

      if( use_approximate )
      {
        // Approximate search: sample a fraction of the index
        size_t sample_size = static_cast< size_t >(
          index.size() * m_nn_sample_fraction );
        sample_size = std::max( sample_size, k * 2 ); // At least 2x k
        sample_size = std::min( sample_size, index.size() ); // Cap at index size

        // Create a vector of keys and sample randomly
        std::vector< std::string > keys;
        keys.reserve( index.size() );
        for( const auto& entry : index )
        {
          keys.push_back( entry.first );
        }

        // Shuffle and take first sample_size keys
        std::random_device rd;
        std::mt19937 gen( rd() );
        std::shuffle( keys.begin(), keys.end(), gen );

        for( size_t i = 0; i < sample_size; ++i )
        {
          const auto& key = keys[i];
          const auto& vec = index.at( key );
          double dist = compute_distance( query, vec );

          if( pq.size() < k )
          {
            pq.push( { dist, key } );
          }
          else if( dist < pq.top().first )
          {
            pq.pop();
            pq.push( { dist, key } );
          }
        }
      }
      else
      {
        // Exact linear search
        for( const auto& entry : index )
        {
          double dist = compute_distance( query, entry.second );

          if( pq.size() < k )
          {
            pq.push( { dist, entry.first } );
          }
          else if( dist < pq.top().first )
          {
            pq.pop();
            pq.push( { dist, entry.first } );
          }
        }
      }
    }

    // Convert to vector
    std::vector< std::pair< std::string, double > > result;
    result.reserve( pq.size() );
    while( !pq.empty() )
    {
      result.emplace_back( pq.top().second, pq.top().first );
      pq.pop();
    }

    // Reverse to get closest first
    std::reverse( result.begin(), result.end() );
    return result;
  }

  unsigned m_pos_seed_neighbors;
  int m_kernel_type = HISTOGRAM;
  double m_c = 2.0;
  double m_gamma = 0.0078125;
  unsigned m_nn_max_linear_search = 50000;
  double m_nn_sample_fraction = 0.1;
  unsigned m_autoneg_select_ratio = 0;
  std::string m_nn_distance_method = "euclidean";
  bool m_use_platt_scaling = true;
  bool m_force_exemplar_scores = false;

  std::unordered_map< std::string, descriptor_element > m_positive_descriptors;
  std::unordered_map< std::string, descriptor_element > m_negative_descriptors;
  std::unordered_map< std::string, descriptor_element > m_working_index;

  // Reference to full index for auto-negative selection
  const std::unordered_map< std::string, std::vector< double > >* m_full_index_ref = nullptr;

  // Reference to LSH index for fast approximate NN search
  const lsh_index* m_lsh_index_ref = nullptr;
  unsigned m_lsh_neighbor_multiplier = 10;

  // Whether to invert probabilities (determined during ordered_results)
  bool m_invert_probabilities = false;

  svm_model* m_svm_model;
};

//--------------------------------------------------------------------------------
// Private implementation class
class process_query_process::priv
{
public:
  priv()
    : m_descriptor_index_file( "" )
    , m_conn_str( "" )
    , m_pos_seed_neighbors( 500 )
    , m_query_return_size( 300 )
    , m_svm_kernel_type( "histogram" )
    , m_svm_c( 2.0 )
    , m_svm_gamma( 0.0078125 )
    , m_nn_max_linear_search( 50000 )
    , m_nn_sample_fraction( 0.1 )
    , m_autoneg_select_ratio( 0 )
    , m_use_lsh_index( true )
    , m_lsh_bit_length( 256 )
    , m_lsh_neighbor_multiplier( 10 )
    , m_use_platt_scaling( true )
    , m_force_exemplar_scores( false )
    , m_index_loaded( false )
    , m_lsh_loaded( false )
    , m_iqr_session( nullptr )
    , m_logger( kwiver::vital::get_logger( "viame.svm.process_query" ) ) {}

  ~priv() {}

  std::string m_descriptor_index_file;
  std::string m_conn_str;
  unsigned m_pos_seed_neighbors;
  unsigned m_query_return_size;
  std::string m_svm_kernel_type;
  double m_svm_c;
  double m_svm_gamma;
  unsigned m_nn_max_linear_search;
  double m_nn_sample_fraction;
  unsigned m_autoneg_select_ratio;

  // LSH configuration
  bool m_use_lsh_index;
  std::string m_lsh_hash_codes_file;
  std::string m_lsh_hash_uids_file;
  std::string m_itq_mean_vec_file;
  std::string m_itq_rotation_file;
  unsigned m_lsh_bit_length;
  unsigned m_lsh_neighbor_multiplier;
  std::string m_nn_distance_method;
  bool m_use_platt_scaling;
  bool m_force_exemplar_scores;

  bool m_index_loaded;
  bool m_lsh_loaded;

  // Full descriptor index
  std::unordered_map< std::string, std::vector< double > > m_descriptor_index;

  // LSH index for fast approximate NN search
  lsh_index m_lsh_index;

  // IQR session
  std::unique_ptr< iqr_session > m_iqr_session;

  kwiver::vital::logger_handle_t m_logger;

  void load_descriptor_index()
  {
#ifdef VIAME_ENABLE_CPPDB
    if( !m_conn_str.empty() )
    {
      load_descriptor_index_from_db();
      return;
    }
#endif

    load_descriptor_index_from_csv();
  }

  void load_descriptor_index_from_csv()
  {
    if( m_descriptor_index_file.empty() )
    {
      throw std::runtime_error(
        "Either descriptor_index_file or conn_str must be provided" );
    }

    std::ifstream file( m_descriptor_index_file );

    if( !file.is_open() )
    {
      throw std::runtime_error( "Failed to open descriptor index file: " +
        m_descriptor_index_file );
    }

    std::string line;
    while( std::getline( file, line ) )
    {
      if( line.empty() ) continue;

      std::istringstream ss( line );
      std::string uid;

      if( !std::getline( ss, uid, ',' ) ) continue;

      std::vector< double > values;
      std::string value_str;
      while( std::getline( ss, value_str, ',' ) )
      {
        try { values.push_back( std::stod( value_str ) ); }
        catch( const std::exception& ) {}
      }

      if( !values.empty() )
      {
        m_descriptor_index[uid] = std::move( values );
      }
    }

    m_index_loaded = true;
  }

#ifdef VIAME_ENABLE_CPPDB
  void load_descriptor_index_from_db()
  {
    ::cppdb::session conn( m_conn_str );

    // Query all descriptors from the DESCRIPTOR table
    ::cppdb::result res = conn.create_statement(
      "SELECT UID, VECTOR_DATA FROM DESCRIPTOR" ).query();

    while( res.next() )
    {
      std::string uid;
      std::string vector_data;

      res.fetch( 0, uid );
      res.fetch( 1, vector_data );

      // Parse comma-separated vector data
      std::vector< double > values;
      std::istringstream ss( vector_data );
      std::string value_str;
      while( std::getline( ss, value_str, ',' ) )
      {
        try { values.push_back( std::stod( value_str ) ); }
        catch( const std::exception& ) {}
      }

      if( !values.empty() )
      {
        m_descriptor_index[uid] = std::move( values );
      }
    }

    conn.close();
    m_index_loaded = true;
  }
#endif
};

// ===============================================================================

process_query_process
::process_query_process( config_block_sptr const& config )
  : process( config ),
    d( new process_query_process::priv() )
{
  make_ports();
  make_config();
}


process_query_process
::~process_query_process()
{
}


// -------------------------------------------------------------------------------
void
process_query_process
::_configure()
{
  d->m_descriptor_index_file = config_value_using_trait( descriptor_index_file );
  d->m_conn_str = config_value_using_trait( conn_str );
  d->m_pos_seed_neighbors = config_value_using_trait( pos_seed_neighbors );
  d->m_query_return_size = config_value_using_trait( query_return_size );
  d->m_svm_kernel_type = config_value_using_trait( svm_kernel_type );
  d->m_svm_c = config_value_using_trait( svm_c );
  d->m_svm_gamma = config_value_using_trait( svm_gamma );
  d->m_nn_max_linear_search = config_value_using_trait( nn_max_linear_search );
  d->m_nn_sample_fraction = config_value_using_trait( nn_sample_fraction );
  d->m_autoneg_select_ratio = config_value_using_trait( autoneg_select_ratio );

  // LSH configuration
  d->m_use_lsh_index = config_value_using_trait( use_lsh_index );
  d->m_lsh_hash_codes_file = config_value_using_trait( lsh_hash_codes_file );
  d->m_lsh_hash_uids_file = config_value_using_trait( lsh_hash_uids_file );
  d->m_itq_mean_vec_file = config_value_using_trait( itq_mean_vec_file );
  d->m_itq_rotation_file = config_value_using_trait( itq_rotation_file );
  d->m_lsh_bit_length = config_value_using_trait( lsh_bit_length );
  d->m_lsh_neighbor_multiplier = config_value_using_trait( lsh_neighbor_multiplier );
  d->m_nn_distance_method = config_value_using_trait( nn_distance_method );
  d->m_use_platt_scaling = config_value_using_trait( use_platt_scaling );
  d->m_force_exemplar_scores = config_value_using_trait( force_exemplar_scores );

  d->load_descriptor_index();

  // Try to load LSH index if enabled
  d->m_lsh_loaded = false;
  if( d->m_use_lsh_index )
  {
    d->m_lsh_loaded = d->m_lsh_index.load(
      d->m_lsh_hash_codes_file,
      d->m_lsh_hash_uids_file,
      d->m_itq_mean_vec_file,
      d->m_itq_rotation_file,
      d->m_lsh_bit_length );

    if( d->m_lsh_loaded )
    {
      LOG_INFO( d->m_logger, "Loaded LSH index with "
        << d->m_lsh_index.size() << " descriptors ("
        << d->m_lsh_bit_length << " bits)" );
    }
    else
    {
      throw std::runtime_error(
        "Failed to load LSH index. use_lsh_index is enabled but required files "
        "are missing or invalid. Check that the following files exist:\n"
        "  - " + d->m_lsh_hash_codes_file + "\n"
        "  - " + d->m_lsh_hash_uids_file + "\n"
        "  - " + d->m_itq_mean_vec_file + "\n"
        "  - " + d->m_itq_rotation_file + "\n"
        "These files are generated by generate_nn_index.py."
        "Set use_lsh_index to false to use brute-force NN search instead." );
    }
  }

  // Create IQR session
  d->m_iqr_session = std::make_unique< iqr_session >( d->m_pos_seed_neighbors );
  d->m_iqr_session->set_kernel_type( d->m_svm_kernel_type );
  d->m_iqr_session->set_c( d->m_svm_c );
  d->m_iqr_session->set_gamma( d->m_svm_gamma );
  d->m_iqr_session->set_nn_max_linear_search( d->m_nn_max_linear_search );
  d->m_iqr_session->set_nn_sample_fraction( d->m_nn_sample_fraction );
  d->m_iqr_session->set_autoneg_select_ratio( d->m_autoneg_select_ratio );
  d->m_iqr_session->set_full_index_ref( &d->m_descriptor_index );

  // Set LSH index reference if loaded
  if( d->m_lsh_loaded )
  {
    d->m_iqr_session->set_lsh_index_ref( &d->m_lsh_index );
    d->m_iqr_session->set_lsh_neighbor_multiplier( d->m_lsh_neighbor_multiplier );
  }
  d->m_iqr_session->set_nn_distance_method( d->m_nn_distance_method );
  d->m_iqr_session->set_use_platt_scaling( d->m_use_platt_scaling );
  d->m_iqr_session->set_force_exemplar_scores( d->m_force_exemplar_scores );
}


// -------------------------------------------------------------------------------
void
process_query_process
::_step()
{
  // Grab inputs
  kwiver::vital::descriptor_set_sptr pos_desc_set =
    grab_from_port_using_trait( positive_descriptor_set );
  kwiver::vital::string_vector_sptr pos_uids =
    grab_from_port_using_trait( positive_exemplar_uids );
  kwiver::vital::descriptor_set_sptr neg_desc_set =
    grab_from_port_using_trait( negative_descriptor_set );
  kwiver::vital::string_vector_sptr neg_uids =
    grab_from_port_using_trait( negative_exemplar_uids );
  kwiver::vital::string_vector_sptr iqr_pos_uids =
    grab_from_port_using_trait( iqr_positive_uids );
  kwiver::vital::string_vector_sptr iqr_neg_uids =
    grab_from_port_using_trait( iqr_negative_uids );
  kwiver::vital::uchar_vector_sptr iqr_model =
    grab_from_port_using_trait( iqr_query_model );

  // Reset IQR session if no feedback (new query)
  if( iqr_pos_uids->empty() && iqr_neg_uids->empty() )
  {
    d->m_iqr_session->reset();
  }

  // Load model from bytes if provided
  if( iqr_model && !iqr_model->empty() )
  {
    d->m_iqr_session->load_model_from_bytes( *iqr_model );
  }

  // Collect positive descriptors from input set
  std::vector< descriptor_element > user_pos_elements;
  {
    auto descriptors = pos_desc_set->descriptors();
    for( size_t i = 0; i < descriptors.size() && i < pos_uids->size(); ++i )
    {
      user_pos_elements.emplace_back( (*pos_uids)[i], descriptors[i]->as_double() );
    }
  }

  // Collect negative descriptors from input set
  std::vector< descriptor_element > user_neg_elements;
  {
    auto descriptors = neg_desc_set->descriptors();
    for( size_t i = 0; i < descriptors.size() && i < neg_uids->size(); ++i )
    {
      user_neg_elements.emplace_back( (*neg_uids)[i], descriptors[i]->as_double() );
    }
  }

  // Collect positive descriptors from IQR feedback UIDs
  std::vector< descriptor_element > iqr_pos_elements;
  for( const std::string& uid : *iqr_pos_uids )
  {
    auto it = d->m_descriptor_index.find( uid );
    if( it != d->m_descriptor_index.end() )
    {
      iqr_pos_elements.emplace_back( uid, it->second );
    }
  }

  // Collect negative descriptors from IQR feedback UIDs
  std::vector< descriptor_element > iqr_neg_elements;
  for( const std::string& uid : *iqr_neg_uids )
  {
    auto it = d->m_descriptor_index.find( uid );
    if( it != d->m_descriptor_index.end() )
    {
      iqr_neg_elements.emplace_back( uid, it->second );
    }
  }

  // Adjudicate with user-provided examples
  d->m_iqr_session->adjudicate( user_pos_elements, user_neg_elements );

  // Adjudicate with IQR feedback
  d->m_iqr_session->adjudicate( iqr_pos_elements, iqr_neg_elements );

  // Update working index with nearest neighbors
  d->m_iqr_session->update_working_index( d->m_descriptor_index );

  // Train SVM and refine
  d->m_iqr_session->refine();

  // Get ordered results
  auto ordered_results = d->m_iqr_session->ordered_results();

  // Get feedback descriptors
  auto ordered_feedback = d->m_iqr_session->ordered_feedback();

  // Limit results if configured
  if( d->m_query_return_size > 0 )
  {
    if( ordered_results.size() > d->m_query_return_size )
    {
      ordered_results.resize( d->m_query_return_size );
    }
    if( ordered_feedback.size() > d->m_query_return_size )
    {
      ordered_feedback.resize( d->m_query_return_size );
    }
  }

  // Build output vectors
  auto result_uids_vec = std::make_shared< kwiver::vital::string_vector >();
  auto result_scores_vec = std::make_shared< kwiver::vital::double_vector >();
  auto feedback_uids_vec = std::make_shared< kwiver::vital::string_vector >();
  auto feedback_dists_vec = std::make_shared< kwiver::vital::double_vector >();
  auto feedback_scores_vec = std::make_shared< kwiver::vital::double_vector >();

  for( const auto& r : ordered_results )
  {
    result_uids_vec->push_back( r.first );
    result_scores_vec->push_back( r.second );
  }

  // Compute feedback scores as linear interpolation from 1 to 0
  double n_feedback = static_cast< double >( ordered_feedback.size() );
  for( size_t i = 0; i < ordered_feedback.size(); ++i )
  {
    feedback_uids_vec->push_back( ordered_feedback[i].first );
    feedback_dists_vec->push_back( ordered_feedback[i].second );
    feedback_scores_vec->push_back( n_feedback > 1 ?
      1.0 - static_cast< double >( i ) / ( n_feedback - 1.0 ) : 1.0 );
  }

  // Get SVM model bytes
  auto model_bytes = d->m_iqr_session->get_model_bytes();
  auto result_model_vec = std::make_shared< kwiver::vital::uchar_vector >(
    model_bytes.begin(), model_bytes.end() );

  // Push outputs
  push_to_port_using_trait( result_uids, result_uids_vec );
  push_to_port_using_trait( result_scores, result_scores_vec );
  push_to_port_using_trait( feedback_uids, feedback_uids_vec );
  push_to_port_using_trait( feedback_distances, feedback_dists_vec );
  push_to_port_using_trait( feedback_scores, feedback_scores_vec );
  push_to_port_using_trait( result_model, result_model_vec );
}


// -------------------------------------------------------------------------------
void
process_query_process
::make_ports()
{
  sprokit::process::port_flags_t optional;

  sprokit::process::port_flags_t required;
  required.insert( flag_required );

  // -- inputs --
  declare_input_port_using_trait( positive_descriptor_set, required );
  declare_input_port_using_trait( positive_exemplar_uids, required );
  declare_input_port_using_trait( negative_descriptor_set, optional );
  declare_input_port_using_trait( negative_exemplar_uids, optional );
  declare_input_port_using_trait( iqr_positive_uids, optional );
  declare_input_port_using_trait( iqr_negative_uids, optional );
  declare_input_port_using_trait( iqr_query_model, optional );

  // -- outputs --
  declare_output_port_using_trait( result_uids, optional );
  declare_output_port_using_trait( result_scores, optional );
  declare_output_port_using_trait( feedback_uids, optional );
  declare_output_port_using_trait( feedback_distances, optional );
  declare_output_port_using_trait( feedback_scores, optional );
  declare_output_port_using_trait( result_model, optional );
}


// -------------------------------------------------------------------------------
void
process_query_process
::make_config()
{
  declare_config_using_trait( descriptor_index_file );
  declare_config_using_trait( conn_str );
  declare_config_using_trait( pos_seed_neighbors );
  declare_config_using_trait( query_return_size );
  declare_config_using_trait( svm_kernel_type );
  declare_config_using_trait( svm_c );
  declare_config_using_trait( svm_gamma );
  declare_config_using_trait( nn_max_linear_search );
  declare_config_using_trait( nn_sample_fraction );
  declare_config_using_trait( autoneg_select_ratio );

  // LSH configuration
  declare_config_using_trait( use_lsh_index );
  declare_config_using_trait( lsh_hash_codes_file );
  declare_config_using_trait( lsh_hash_uids_file );
  declare_config_using_trait( itq_mean_vec_file );
  declare_config_using_trait( itq_rotation_file );
  declare_config_using_trait( lsh_bit_length );
  declare_config_using_trait( lsh_neighbor_multiplier );
  declare_config_using_trait( nn_distance_method );
  declare_config_using_trait( use_platt_scaling );
  declare_config_using_trait( force_exemplar_scores );
}

} // end namespace svm

} // end namespace viame
