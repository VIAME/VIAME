# =============================================================================
# Title: Train Detector - MMDET Cfrnn.habcam
#
# Description: Configuration for training Cascade R-CNN. Uses the MMDetection
# deep learning framework. Input resolution: 1333px. Optimized settings for
# HabCam underwater imagery.
# =============================================================================

#  Groundtruth file extensions (txt, kw18, etc...). Note: this is indepedent of
#  the format that's stored in the file.
groundtruth_extensions = .csv

#  Algorithm to use for 'groundtruth_reader'.
#  Must be one of the following options:
#  	- habcam :: Reads habcam detection/ground truth files.
#  	- kw18 :: Detected object set reader using kw18 format.
groundtruth_reader:type = habcam

#  Can be either: "one_per_file" or "one_per_folder".
groundtruth_style = one_per_folder

#  Semicolon list of seperated image extensions to use in training, images
#  without this extension will not be included.
image_extensions = .jpg;.jpeg;.JPG;.JPEG;.tif;.tiff;.TIF;.TIFF;.png;.PNG;.sgi;.SGI;.bmp;.BMP;.pgm;.PGM

#  Semicolon list of seperated video extensions to use in training, videos
#  without this extension will not be included.
video_extensions = .mp4;.MP4;.mpg;.MPG;.mpeg;.MPEG;.avi;.AVI;.wmv;.WMV;.mov;.MOV;.webm;.WEBM;.ogg;.OGG

#  Pipeline to use to extract video frames if inputs are videos
relativepath video_extractor = filter_default.pipe

#  Percent [0.0, 1.0] of validation samples to use if no manual files specified.
default_percent_validation = 0.10

#  Number of validation frames to group together in one test burst
validation_burst_frame_count = 10

#  Pipeline template file.
relativepath pipeline_template = templates/embedded_mmdet.pipe

#  Augmentation pipeline.
relativepath augmentation_pipeline = train_aug_split.pipe

#  Augmentatation cache.
augmentation_cache = augmented_images

#  Do not regenerate cache.
regenerate_cache = true


#  Algorithm to use for 'detector_trainer'.
#  Must be one of the following options: darket, scallop_tk, mmdet, ocv_windowed
detector_trainer:type = ocv_windowed

block detector_trainer:ocv_windowed

  # Directory for all files used in training
  train_directory = deep_training

  # Windowing mode, can be disabled, maintain_ar, scale, chip, adaptive
  mode = adaptive

  # Image scaling factor used when mode is scale or chip
  scale = 1.2

  # When in chip mode, the chip width.
  chip_width = 1333

  # When in chip mode, the chip height.
  chip_height = 800

  # When in chip mode, the chip step size between chips.
  chip_step_height = 1100

  # When in chip mode, the chip step size between chips.
  chip_step_width = 600

  # If using adaptive selection, total pixel count at which we start to chip
  chip_adaptive_thresh = 2000000

  # Don't train on chips with detections smaller than this
  min_train_box_length = 5

  # Sub-sample chips
  chip_random_factor = 0.10

  # Ensure input images are standard formats
  ensure_standard = true

  # Image reader type
  image_reader:type = vxl

endblock

block detector_trainer:ocv_windowed:trainer

  # Trainer type
  type = mmdet

  #  Configuration File
  relativepath mmdet:config_file = templates/detector_mmdet.py

  #  Seed Weights
  relativepath mmdet:seed_weights = models/cfrnn_seed.pth

  #  Training temp directory
  mmdet:train_directory = deep_training

  #  GPU Count, set as -1 to auto-detect and use maximum
  mmdet:gpu_count = -1

  #  Launch type, can be: none, pytorch, slurm, or mpi
  mmdet:launcher = pytorch

  #  Random numeric seed for weights
  mmdet:random_seed = none

  #  Should validation be run every epoch?
  mmdet:validate = true

endblock

